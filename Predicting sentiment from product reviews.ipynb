{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "\n",
    "DATA_DIR = './data/week1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      "name      183213 non-null object\n",
      "review    182702 non-null object\n",
      "rating    183531 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.2+ MB\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_baby_csv = pd.read_csv(DATA_DIR + 'amazon_baby.csv')\n",
    "\n",
    "amazon_baby_csv.info()\n",
    "print('\\n')\n",
    "amazon_baby_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_ponctuation(s):\n",
    "    s = s.translate(None, string.punctuation)\n",
    "    return s\n",
    "\n",
    "# remove ponctuation from the review colum\n",
    "amazon_baby_csv['review'] = amazon_baby_csv['review'].fillna('')\n",
    "amazon_baby_csv['review'] = amazon_baby_csv['review'].apply(remove_ponctuation)\n",
    "\n",
    "# remove ratings < 3 and create a sentiment column\n",
    "amazon_baby_csv = amazon_baby_csv[amazon_baby_csv['rating'] != 3]\n",
    "amazon_baby_csv['sentiment'] = amazon_baby_csv['rating'].apply(lambda x: 1 if x > 3 else -1)\n",
    "\n",
    "# Split the dataframe into a training and test set\n",
    "train_indices = open(DATA_DIR + 'module-2-assignment-train-idx.json').read()\n",
    "train_indices = json.loads(train_indices)\n",
    "test_indices = open(DATA_DIR + 'module-2-assignment-test-idx.json').read()\n",
    "test_indices = json.loads(test_indices)\n",
    "train_amazon_baby = amazon_baby_csv.iloc[train_indices]\n",
    "test_amazon_baby = amazon_baby_csv.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words Model\n",
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct bag-of-words features\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_amazon_baby['review'])\n",
    "test_matrix = vectorizer.transform(test_amazon_baby['review'])\n",
    "\n",
    "# Train the logistic regression model\n",
    "sentiment_model = LogisticRegression()\n",
    "sentiment_model.fit(train_matrix, train_amazon_baby['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### How many weights are >= 0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 85974 positives coefficients in the sentiment model.\n"
     ]
    }
   ],
   "source": [
    "positive_coef = np.sum(sentiment_model.coef_ >= 0)\n",
    "print('There are %s positives coefficients in the sentiment model.' % positive_coef) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the score given by the decision function we can deduce that the predictions are : 1 -1 -1.\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_amazon_baby.iloc[10:13]\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review'])\n",
    "sample_test_scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "predictions = np.empty(3)\n",
    "predictions.fill(-1) \n",
    "predictions[sample_test_scores > 0] = 1\n",
    "\n",
    "print('Based on the score given by the decision function we can deduce that the predictions are : %s %s %s.' % \n",
    "      (int(predictions[0]), int(predictions[1]), int(predictions[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction previously computed matches the predictions given by the model : 1 -1 -1.\n"
     ]
    }
   ],
   "source": [
    "sample_test_predictions = sentiment_model.predict(sample_test_matrix)\n",
    "\n",
    "print('The prediction previously computed matches the predictions given by the model : %s %s %s.' % \n",
    "      (int(sample_test_predictions[0]), int(sample_test_predictions[1]), int(sample_test_predictions[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Of the three data points in sample_test_data, which one (first, second, or third) has the lowest probability of being classified as a positive review ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the score given by the decision function we can compute the probabilities that a given review        is positive using the sigmoid function. The probabilities are : 0.996337061949, 0.0411715733413 and 2.96845484816e-05.\n",
      "\n",
      "\n",
      "So it is the third data point that has the lowest probability of being classified as a positive review.\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    proba = 1 / (1 + np.exp(-z))\n",
    "    return proba\n",
    "    \n",
    "probabilities = []\n",
    "for score in sample_test_scores:\n",
    "    proba = sigmoid(score)\n",
    "    probabilities.append(proba)\n",
    "    \n",
    "print('Based on the score given by the decision function we can compute the probabilities that a given review \\\n",
    "       is positive using the sigmoid function. The probabilities are : %s, %s and %s.' % \n",
    "      (probabilities[0], probabilities[1], probabilities[2]))\n",
    "print('\\n')\n",
    "print('So it is the third data point that has the lowest probability of being classified as a positive review.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which of the following products are represented in the 20 most positive reviews ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most positive products are : \n",
      "\n",
      "114796    Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
      "80155     Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
      "87017       Baby Einstein Around The World Discovery Center\n",
      "168081    Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
      "137034           Graco Pack 'n Play Element Playard - Flint\n",
      "100166    Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
      "180646        Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
      "52631     Evenflo X Sport Plus Convenience Stroller - Ch...\n",
      "168697    Graco FastAction Fold Jogger Click Connect Str...\n",
      "50315            P'Kolino Silly Soft Seating in Tias, Green\n",
      "133651                    Britax 2012 B-Agile Stroller, Red\n",
      "66059          Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
      "97325     Freemie Hands-Free Concealable Breast Pump Col...\n",
      "119182    Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
      "140816           Diono RadianRXT Convertible Car Seat, Plum\n",
      "147949    Baby Jogger City Mini GT Single Stroller, Shad...\n",
      "22586        Britax Decathlon Convertible Car Seat, Tiffany\n",
      "165593    Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
      "182089    Summer Infant Wide View Digital Color Video Mo...\n",
      "147996    Baby Jogger City Mini GT Double Stroller, Shad...\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_probas = sentiment_model.predict_proba(test_matrix)\n",
    "test_positive_probas = test_probas[:,1]\n",
    "most_positive_probas = list(test_positive_probas.argsort()[::-1][0:20])\n",
    "most_positive_baby = test_amazon_baby.iloc[most_positive_probas]\n",
    "\n",
    "print('The most positive products are : \\n')\n",
    "print(most_positive_baby['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which of the following products are represented in the 20 most negative reviews ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most negative products are : \n",
      "\n",
      "16042           Fisher-Price Ocean Wonders Aquarium Bouncer\n",
      "120209    Levana Safe N'See Digital Video Baby Monitor w...\n",
      "77072        Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
      "48694     Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
      "155287    VTech Communications Safe &amp; Sounds Full Co...\n",
      "94560     The First Years True Choice P400 Premium Digit...\n",
      "53207                   Safety 1st High-Def Digital Monitor\n",
      "81332                 Cloth Diaper Sprayer--styles may vary\n",
      "113995    Motorola Digital Video Baby Monitor with Room ...\n",
      "10677                     Philips AVENT Newborn Starter Set\n",
      "9915           Cosco Alpha Omega Elite Convertible Car Seat\n",
      "59546                Ellaroo Mei Tai Baby Carrier - Hershey\n",
      "172090    Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...\n",
      "75994            Peg-Perego Tatamia High Chair, White Latte\n",
      "40079     Chicco Cortina KeyFit 30 Travel System in Adve...\n",
      "149987                     NUK Cook-n-Blend Baby Food Maker\n",
      "154878    VTech Communications Safe &amp; Sound Digital ...\n",
      "1116                  Safety 1st Deluxe 4-in-1 Bath Station\n",
      "83234         Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs\n",
      "31741                Regalo My Cot Portable Bed, Royal Blue\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_probas = sentiment_model.predict_proba(test_matrix)\n",
    "test_negative_probas = test_probas[:,1]\n",
    "most_negative_probas = list(test_positive_probas.argsort()[0:20])\n",
    "most_negative_baby = test_amazon_baby.iloc[most_negative_probas]\n",
    "\n",
    "print('The most negative products are : \\n')\n",
    "print(most_negative_baby['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the accuracy of the sentiment_model on the test_data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test data is 0.932265418766.\n"
     ]
    }
   ],
   "source": [
    "test_predictions = sentiment_model.predict(test_matrix)\n",
    "\n",
    "accuracy = accuracy_score(test_amazon_baby['sentiment'], test_predictions)\n",
    "\n",
    "print('The accuracy on the test data is %s.' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does a higher accuracy value on the training_data always imply that the classifier is better ?\n",
    "\n",
    "No because the model might have overfit the training data thus would generalyze poorly on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words Model with reduced vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "                     'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "                     'work', 'product', 'money', 'would', 'return']\n",
    "\n",
    "# Construct bag-of-words features \n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words)\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_amazon_baby['review'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_amazon_baby['review'])\n",
    "\n",
    "# Train the logistic regression features\n",
    "simple_model = LogisticRegression()\n",
    "simple_model.fit(train_matrix_word_subset, train_amazon_baby['sentiment'])\n",
    "\n",
    "# Construct dataframe to store (word, coefficient) pairs\n",
    "simple_model_data = {\n",
    "    'words': significant_words,\n",
    "    'coefs': simple_model.coef_[0,:]\n",
    "}\n",
    "simple_model_coef_table = pd.DataFrame(data=simple_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### How many of the 20 coefficients (corresponding to the 20 significant_words) are positive for the simple_model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 positive coefficients for the simple model.\n"
     ]
    }
   ],
   "source": [
    "simple_model_positive_coefs = np.sum(simple_model.coef_ > 0) \n",
    "\n",
    "print('There are %s positive coefficients for the simple model.' % simple_model_positive_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the positive words in the simple_model also positive words in the sentiment_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients for the words in the sentiment model are : 1.57301531631, 1.22507913667, 1.35195262572, 0.0548859014267, 0.638852688253, 1.86278360017, 1.51794273443, 0.541220062444, 0.389968628061, 0.124447349271.\n",
      "\n",
      "\n",
      "We can see that the coefficients are all positive so the words in the sentiment model are also positive words.\n"
     ]
    }
   ],
   "source": [
    "positive_words = list(simple_model_coef_table['words'].iloc[np.arange(10)])\n",
    "indices_positive_words = [ vectorizer.vocabulary_[word] for word in positive_words]\n",
    "\n",
    "sentiment_model_coefs = sentiment_model.coef_[0,:]\n",
    "coefs_positive_words_subset = sentiment_model_coefs[indices_positive_words]\n",
    "coefs_positive_words_subset = [str(coef) for coef in coefs_positive_words_subset]\n",
    "print('The coefficients for the words in the sentiment model are : ' + ', '.join(coefs_positive_words_subset) + '.')\n",
    "print('\\n')\n",
    "print('We can see that the coefficients are all positive so the words in the sentiment model are also positive words.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the sentiment model on the train data is 0.967912394316.\n"
     ]
    }
   ],
   "source": [
    "train_predictions = sentiment_model.predict(train_matrix)\n",
    "accuracy = accuracy_score(train_amazon_baby['sentiment'], train_predictions)\n",
    "\n",
    "print('The accuracy for the sentiment model on the train data is %s.' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the sentiment model on the train data is 0.866822570007.\n"
     ]
    }
   ],
   "source": [
    "train_predictions_subset = simple_model.predict(train_matrix_word_subset)\n",
    "accuracy_subset = accuracy_score(train_amazon_baby['sentiment'], train_predictions_subset)\n",
    "\n",
    "print('The accuracy for the sentiment model on the train data is %s.' % accuracy_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which model (sentiment_model or simple_model) has higher accuracy on the TRAINING set ?\n",
    "\n",
    "It is the sentiment_model that has the higher accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the simple model on the test data is 0.869360451164.\n"
     ]
    }
   ],
   "source": [
    "test_predictions_subset = simple_model.predict(test_matrix_word_subset)\n",
    "accuracy = accuracy_score(test_amazon_baby['sentiment'], test_predictions_subset)\n",
    "\n",
    "print('The accuracy for the simple model on the test data is %s.' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the dummy classifier on the train data is 0.732460874258.\n"
     ]
    }
   ],
   "source": [
    "dummy_classifier = DummyClassifier()\n",
    "dummy_classifier.fit(train_matrix, train_amazon_baby['sentiment'])\n",
    "train_predictions = dummy_classifier.predict(train_matrix)\n",
    "accuracy = accuracy_score(train_amazon_baby['sentiment'], train_predictions)\n",
    "\n",
    "print('The accuracy for the dummy classifier on the train data is %s.' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the sentiment_model definitely better than the majority class classifier (the baseline)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
